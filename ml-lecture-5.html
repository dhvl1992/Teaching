<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How Neural Networks Learn: Gradient Descent</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            line-height: 1.6;
            color: #1E293B;
            background: linear-gradient(135deg, #FEF7ED 0%, #1E293B 100%);
            scroll-behavior: smooth;
        }

        .presentation-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .slide {
            background: #FEF7ED;
            margin: 40px 0;
            padding: 60px;
            border-radius: 20px;
            border-left: 5px solid #EA580C;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            min-height: 80vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            opacity: 0;
            transform: translateY(50px);
            transition: all 0.8s ease;
        }

        .slide.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .slide h1 {
            color: #1E293B;
            font-size: 3.5rem;
            margin-bottom: 30px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }

        .slide h2 {
            color: #1E293B;
            font-size: 2.5rem;
            margin-bottom: 25px;
            border-bottom: 3px solid #EA580C;
            padding-bottom: 10px;
        }

        .slide h3 {
            color: #059669;
            font-size: 1.8rem;
            margin: 20px 0 15px 0;
        }

        .slide p {
            font-size: 1.3rem;
            margin-bottom: 20px;
            text-align: justify;
        }

        .image-container {
            text-align: center;
            margin: 30px 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 20px rgba(0,0,0,0.15);
            transition: transform 0.3s ease;
        }

        .image-container img:hover {
            transform: scale(1.05);
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            align-items: center;
        }

        .math-equation {
            background: rgba(5, 150, 105, 0.05);
            padding: 20px;
            border-radius: 10px;
            border-left: 5px solid #059669;
            font-family: 'Courier New', monospace;
            font-size: 1.2rem;
            margin: 20px 0;
            text-align: center;
        }

        .highlight-box {
            background: #059669;
            color: #FEF7ED;
            padding: 25px;
            border-radius: 15px;
            margin: 25px 0;
            text-align: center;
            font-size: 1.2rem;
            font-weight: bold;
        }

        .key-insight {
            background: rgba(234, 88, 12, 0.1);
            border-left: 5px solid #EA580C;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 10px 10px 0;
        }

        .key-insight strong {
            color: #EA580C;
        }

        .navigation {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(254, 247, 237, 0.9);
            padding: 15px;
            border-radius: 50px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }

        .nav-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #1E293B;
            margin: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .nav-dot.active {
            background: #EA580C;
            transform: scale(1.3);
        }

        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: #EA580C;
            transition: width 0.3s ease;
            z-index: 1000;
        }

        .interactive-demo {
            background: rgba(5, 150, 105, 0.05);
            padding: 30px;
            border-radius: 15px;
            margin: 30px 0;
            text-align: center;
        }

        .demo-button {
            background: #EA580C;
            color: #FEF7ED;
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            font-size: 1.1rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .demo-button:hover {
            background: #059669;
            transform: translateY(-2px);
        }

        @media (max-width: 768px) {
            .slide {
                padding: 30px;
                margin: 20px 0;
            }
            
            .slide h1 {
                font-size: 2.5rem;
            }
            
            .slide h2 {
                font-size: 2rem;
            }
            
            .two-column {
                grid-template-columns: 1fr;
            }
        }

        .fade-in {
            animation: fadeInUp 1s ease forwards;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>
    
    <div class="presentation-container">
        <!-- Title Slide -->
        <div class="slide" id="slide1">
            <h1>üß† How Neural Networks Learn</h1>
            <div class="image-container">
                <img src="images/ml/thumbnail.png" alt="Neural Network Learning">
            </div>
            <div class="highlight-box">
                <p>Welcome to the fascinating world of Gradient Descent!</p>
                <p>The algorithm that teaches machines to recognize patterns</p>
            </div>
        </div>

        <!-- Recap Slide -->
        <div class="slide" id="slide2">
            <h2>üìö Quick Recap: What Are We Trying to Do?</h2>
            <div class="two-column">
                <div>
                    <h3>Our Goal: Digit Recognition</h3>
                    <p>We want our neural network to look at handwritten digits and correctly identify what number they represent.</p>
                    <div class="key-insight">
                        <strong>The Challenge:</strong> Each digit can be written in countless different ways, but they should all be recognized as the same number!
                    </div>
                </div>
                <div class="image-container">
                    <img src="images/ml/three-3s (1).png" alt="Different ways to write 3">
                </div>
            </div>
            
            <div class="two-column">
                <div class="image-container">
                    <img src="images/ml/pixels-as-input.png" alt="Pixels as input">
                </div>
                <div>
                    <h3>How It Works</h3>
                    <p>Each 28√ó28 pixel image becomes 784 input values (one for each pixel's brightness).</p>
                    <p>These flow through layers of neurons, each with weights and biases, to produce 10 outputs (one for each digit 0-9).</p>
                </div>
            </div>
        </div>

        <!-- The Learning Problem -->
        <div class="slide" id="slide3">
            <h2>ü§î The Big Question: How Does Learning Happen?</h2>
            <div class="image-container">
                <img src="images/ml/neural-network-function.png" alt="Neural network as function">
            </div>
            
            <p>Our network has <strong>13,002 parameters</strong> (weights and biases) that determine its behavior. Initially, these are just random numbers!</p>
            
            <div class="highlight-box">
                The key insight: Learning = Finding the right values for these 13,002 numbers
            </div>
            
            <div class="image-container">
                <img src="images/ml/random-trash.png" alt="Random network output">
            </div>
            <p style="text-align: center; font-style: italic;">With random weights, our network produces "utter trash" üóëÔ∏è</p>
        </div>

        <!-- Cost Function Introduction -->
        <div class="slide" id="slide4">
            <h2>üí∞ The Cost Function: Measuring How Bad We Are</h2>
            
            <p>To improve, we first need to measure how badly our network is performing. This is where the <strong>cost function</strong> comes in!</p>
            
            <div class="two-column">
                <div>
                    <h3>What's the cost of being wrong?</h3>
                    <p>When we show our network a "3", we want the third output neuron to light up (value = 1) and all others to be dim (value = 0).</p>
                    <p>The cost measures how far we are from this ideal.</p>
                </div>
                <div class="image-container">
                    <img src="images/ml/cost-of-difference.png" alt="Cost of difference">
                </div>
            </div>
            
            <div class="math-equation">
                Cost = Œ£ (actual_output - desired_output)¬≤
            </div>
            
            <div class="image-container">
                <img src="images/ml/cost-calculation.png" alt="Cost calculation">
            </div>
        </div>

        <!-- Cost Function Details -->
        <div class="slide" id="slide5">
            <h2>üìä Understanding the Cost Function</h2>
            
            <div class="image-container">
                <img src="images/ml/cost-function.png" alt="Cost function overview">
            </div>
            
            <div class="key-insight">
                <strong>Think of it this way:</strong> The cost function is like a report card. It takes all 13,002 weights and biases as input, tests them on thousands of training examples, and gives back a single number: "How bad is this network?"
            </div>
            
            <p>A <strong>low cost</strong> means the network is doing well. A <strong>high cost</strong> means it's making lots of mistakes.</p>
            
            <div class="interactive-demo">
                <h3>üéØ Interactive Question</h3>
                <div class="image-container">
                    <img src="images/ml/cost-ranking-question.png" alt="Cost ranking question">
                </div>
                <p>Can you rank these outputs from highest cost to lowest cost for classifying a "4"?</p>
                <button class="demo-button" onclick="showAnswer()">Show Answer</button>
                <div id="answer" style="display: none; margin-top: 20px;">
                    <strong>Answer:</strong> B > A > C > D<br>
                    B is worst (confident about wrong answer), D is best (confident about right answer)
                </div>
            </div>
        </div>

        <!-- Minimization Problem -->
        <div class="slide" id="slide6">
            <h2>‚¨áÔ∏è The Minimization Challenge</h2>
            
            <p>Now we have a clear goal: <strong>Find the values of our 13,002 parameters that minimize the cost function.</strong></p>
            
            <div class="two-column">
                <div>
                    <h3>Let's Start Simple</h3>
                    <p>Imagine we only have ONE parameter to optimize. Our cost function would look like a simple curve, and we want to find its minimum.</p>
                    <p>For very simple functions, we could solve this mathematically (find where slope = 0).</p>
                </div>
                <div class="image-container">
                    <img src="images/ml/single-input-cost.png" alt="Single input cost function">
                </div>
            </div>
            
            <div class="highlight-box">
                But with 13,002 dimensions, direct calculation is impossible! We need a smarter approach.
            </div>
            
            <div class="image-container">
                <img src="images/ml/infeasible-minimum.png" alt="Infeasible minimum">
            </div>
        </div>

        <!-- Gradient Descent Introduction -->
        <div class="slide" id="slide7">
            <h2>üèîÔ∏è Enter Gradient Descent: Rolling Downhill</h2>
            
            <div class="key-insight">
                <strong>The Big Idea:</strong> If we can't solve for the minimum directly, let's just roll downhill like a ball!
            </div>
            
            <div class="two-column">
                <div class="image-container">
                    <img src="images/ml/hooray.svg" alt="Following slope">
                </div>
                <div>
                    <h3>The Algorithm (1D version)</h3>
                    <ol style="font-size: 1.2rem; line-height: 1.8;">
                        <li>Start at a random point</li>
                        <li>Check the slope:
                            <ul>
                                <li>If slope is positive ‚Üí move left</li>
                                <li>If slope is negative ‚Üí move right</li>
                            </ul>
                        </li>
                        <li>Take a small step in that direction</li>
                        <li>Repeat until you reach the bottom!</li>
                    </ol>
                </div>
            </div>
            
            <div class="image-container">
                <img src="images/ml/finding-minima.png" alt="Finding minima">
            </div>
        </div>

        <!-- 2D Gradient Descent -->
        <div class="slide" id="slide8">
            <h2>üó∫Ô∏è Scaling Up: Two Dimensions</h2>
            
            <p>Now imagine our cost function has two inputs instead of one. We can visualize this as a landscape with hills and valleys.</p>
            
            <div class="image-container">
                <img src="images/ml/2-input-cost.png" alt="2D cost surface">
            </div>
            
            <div class="two-column">
                <div>
                    <h3>The Gradient Vector</h3>
                    <p>In multiple dimensions, "slope" becomes a <strong>vector</strong> called the <strong>gradient</strong>.</p>
                    <p>The gradient points in the direction of <em>steepest ascent</em>, so the <em>negative gradient</em> points downhill!</p>
                </div>
                <div class="image-container">
                    <img src="images/ml/negative-gradient.png" alt="Negative gradient">
                </div>
            </div>
            
            <div class="math-equation">
                Gradient: ‚àáC (points uphill)<br>
                Negative Gradient: -‚àáC (points downhill)
            </div>
        </div>

        <!-- Following the Gradient -->
        <div class="slide" id="slide9">
            <h2>üéØ Following the Gradient Path</h2>
            
            <div class="image-container">
                <img src="images/ml/follow-slope.png" alt="Following the slope">
            </div>
            
            <div class="highlight-box">
                Gradient Descent Algorithm:<br>
                1. Compute the gradient ‚àáC<br>
                2. Move in the opposite direction: -Œ∑‚àáC<br>
                3. Repeat until convergence
            </div>
            
            <div class="key-insight">
                <strong>Learning Rate (Œ∑):</strong> This controls how big steps we take. Too small = slow learning. Too big = we might overshoot and oscillate around the minimum!
            </div>
            
            <div class="image-container">
                <img src="images/ml/gradient-descent.png" alt="Gradient descent steps">
            </div>
        </div>

        <!-- High Dimensional Thinking -->
        <div class="slide" id="slide10">
            <h2>üåå Thinking in 13,002 Dimensions</h2>
            
            <p>The same principle works in our actual problem with 13,002 dimensions, even though we can't visualize it!</p>
            
            <div class="two-column">
                <div class="image-container">
                    <img src="images/ml/weights-and-gradient.png" alt="Weights and gradient vectors">
                </div>
                <div>
                    <h3>Vector Perspective</h3>
                    <p>Think of all weights and biases as one giant vector with 13,002 components.</p>
                    <p>The gradient is also a vector with 13,002 components, telling us how to nudge each parameter.</p>
                </div>
            </div>
            
            <div class="key-insight">
                <strong>What the gradient tells us:</strong>
                <ul>
                    <li><strong>Direction:</strong> Should this weight increase or decrease?</li>
                    <li><strong>Magnitude:</strong> How important is changing this particular weight?</li>
                </ul>
            </div>
            
            <div class="image-container">
                <img src="images/ml/nudges-on-network.png" alt="Nudges on network">
            </div>
        </div>

        <!-- Weight Importance -->
        <div class="slide" id="slide11">
            <h2>‚öñÔ∏è Not All Weights Are Created Equal</h2>
            
            <div class="image-container">
                <img src="images/ml/weight-importance.png" alt="Weight importance comparison">
            </div>
            
            <p>Some connections in our network have a much bigger impact on the final result than others. The gradient naturally encodes this importance!</p>
            
            <div class="two-column">
                <div>
                    <h3>High Gradient Component</h3>
                    <p>Large change in cost function<br>
                    ‚Üí This weight really matters!<br>
                    ‚Üí Make a bigger adjustment</p>
                </div>
                <div>
                    <h3>Low Gradient Component</h3>
                    <p>Small change in cost function<br>
                    ‚Üí This weight doesn't matter much<br>
                    ‚Üí Make a smaller adjustment</p>
                </div>
            </div>
            
            <div class="highlight-box">
                The gradient automatically tells us which changes will give us the "biggest bang for our buck"!
            </div>
        </div>

        <!-- Training Process -->
        <div class="slide" id="slide12">
            <h2>üèãÔ∏è The Training Process in Action</h2>
            
            <div class="image-container">
                <img src="images/ml/training-data.png" alt="Training data">
            </div>
            
            <h3>Step by Step:</h3>
            <ol style="font-size: 1.2rem; line-height: 2;">
                <li><strong>Feed training data</strong> through the network</li>
                <li><strong>Calculate the cost</strong> (how wrong were we?)</li>
                <li><strong>Compute the gradient</strong> (which way is downhill?)</li>
                <li><strong>Update all weights and biases</strong> (take a step downhill)</li>
                <li><strong>Repeat</strong> with more training data</li>
            </ol>
            
            <div class="two-column">
                <div class="image-container">
                    <img src="images/ml/training-vs-testing.png" alt="Training vs testing">
                </div>
                <div>
                    <div class="key-insight">
                        <strong>The Ultimate Test:</strong> After training, we test the network on completely new data it has never seen before. If it performs well, it has truly "learned"!
                    </div>
                </div>
            </div>
        </div>

        <!-- What's Next -->
        <div class="slide" id="slide13">
            <h2>üîÆ What's Coming Next: Backpropagation</h2>
            
            <p>We've learned <em>what</em> gradient descent does, but how do we actually <em>compute</em> that gradient for a neural network?</p>
            
            <div class="highlight-box">
                That's where <strong>Backpropagation</strong> comes in!<br>
                The ingenious algorithm that efficiently calculates gradients in neural networks.
            </div>
            
            <div class="image-container">
                <img src="images/ml/recap-propagation.png" alt="Network propagation">
            </div>
            
            <div class="key-insight">
                <strong>Preview:</strong> Backpropagation works by starting from the output error and propagating it backwards through the network, computing how much each weight contributed to the mistake.
            </div>
            
            <p>But that's a story for our next lesson! üìö</p>
        </div>

        <!-- Summary -->
        <div class="slide" id="slide14">
            <h2>üéì Key Takeaways</h2>
            
            <div class="highlight-box">
                <h3>üß† Learning = Optimization</h3>
                <p>Neural network learning is really just finding the best values for thousands of parameters by minimizing a cost function.</p>
            </div>
            
            <div class="two-column">
                <div>
                    <h3>üèîÔ∏è Gradient Descent</h3>
                    <ul style="font-size: 1.2rem; line-height: 1.8;">
                        <li>Like rolling a ball downhill</li>
                        <li>Follow the negative gradient</li>
                        <li>Take small steps iteratively</li>
                        <li>Eventually reach a minimum</li>
                    </ul>
                </div>
                <div>
                    <h3>üìä The Gradient Vector</h3>
                    <ul style="font-size: 1.2rem; line-height: 1.8;">
                        <li>Shows direction of steepest ascent</li>
                        <li>Magnitude indicates importance</li>
                        <li>Guides parameter updates</li>
                        <li>Computed via backpropagation</li>
                    </ul>
                </div>
            </div>
            
            <div class="image-container">
                <img src="images/ml/maxresdefault (1).jpg" alt="Neural network visualization">
            </div>
            
            <div class="highlight-box">
                <h3>üöÄ The Journey Continues...</h3>
                <p>Next up: Backpropagation - the algorithm that makes it all possible!</p>
            </div>
        </div>
    </div>

    <script>
        // Intersection Observer for slide animations
        const slides = document.querySelectorAll('.slide');
        const progressBar = document.getElementById('progressBar');

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                    
                    // Update progress bar
                    const slideIndex = Array.from(slides).indexOf(entry.target);
                    const progress = ((slideIndex + 1) / slides.length) * 100;
                    progressBar.style.width = progress + '%';
                }
            });
        }, {
            threshold: 0.3
        });

        slides.forEach(slide => {
            observer.observe(slide);
        });

        // Smooth scrolling for internal links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });

        // Interactive demo function
        function showAnswer() {
            document.getElementById('answer').style.display = 'block';
        }

        // Add some dynamic effects
        window.addEventListener('scroll', () => {
            const scrolled = window.pageYOffset;
            const rate = scrolled * -0.5;
            document.body.style.transform = `translateY(${rate}px)`;
        });

        // Preload images for smooth experience
        function preloadImages() {
            const images = [
                'images/ml/thumbnail.png',
                'images/ml/three-3s (1).png',
                'images/ml/pixels-as-input.png',
                'images/ml/neural-network-function.png',
                'images/ml/random-trash.png',
                'images/ml/cost-of-difference.png',
                'images/ml/cost-calculation.png',
                'images/ml/cost-function.png',
                'images/ml/cost-ranking-question.png',
                'images/ml/single-input-cost.png',
                'images/ml/infeasible-minimum.png',
                'images/ml/hooray.svg',
                'images/ml/finding-minima.png',
                'images/ml/2-input-cost.png',
                'images/ml/negative-gradient.png',
                'images/ml/follow-slope.png',
                'images/ml/gradient-descent.png',
                'images/ml/weights-and-gradient.png',
                'images/ml/nudges-on-network.png',
                'images/ml/weight-importance.png',
                'images/ml/training-data.png',
                'images/ml/training-vs-testing.png',
                'images/ml/recap-propagation.png',
                'images/ml/maxresdefault (1).jpg'
            ];
            
            images.forEach(src => {
                const img = new Image();
                img.src = src;
            });
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            preloadImages();
            
            // Add initial animation to first slide
            setTimeout(() => {
                slides[0].classList.add('visible');
            }, 500);
        });
    </script>
</body>
</html>
