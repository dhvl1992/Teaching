<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Local Search and Optimization - Interactive Learning</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: Georgia, serif;
            background: linear-gradient(135deg, #FEF7ED 0%, #1E293B 100%);
            min-height: 100vh;
            color: #1E293B;
            line-height: 1.6;
            scroll-behavior: smooth;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        /* Progress Bar */
        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: #EA580C;
            transition: width 0.3s ease;
            z-index: 1000;
            box-shadow: 0 2px 4px rgba(234, 88, 12, 0.3);
        }

        /* Enhanced Base slide styling */
        .slide {
            background: #FEF7ED;
            margin-bottom: 30px;
            padding: 40px;
            border-radius: 15px;
            border-left: 5px solid #EA580C;
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
            transition: all 0.5s ease;
            min-height: 500px;
            page-break-after: always;
            opacity: 0;
            transform: translateY(50px);
        }

        .slide.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .slide:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(0,0,0,0.15);
        }

        /* Enhanced images with animations */
        .image-container {
            text-align: center;
            margin: 30px 0;
            overflow: hidden;
            border-radius: 15px;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 20px rgba(0,0,0,0.15);
            transition: all 0.4s ease;
        }

        /* Layout 1: Enhanced Title Slide */
        .title-slide {
            background: #1E293B;
            color: #FEF7ED;
            text-align: center;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            border-left: 5px solid #EA580C;
            position: relative;
            overflow: hidden;
        }

        .title-slide::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(234, 88, 12, 0.1) 0%, transparent 70%);
            animation: float 6s ease-in-out infinite;
        }

        .title-slide h1 {
            font-size: 3.5em;
            margin-bottom: 30px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            animation: slideInFromTop 1s ease-out;
        }

        .title-slide .subtitle {
            font-size: 1.6em;
            opacity: 0.9;
            font-style: italic;
            margin-bottom: 20px;
            animation: slideInFromLeft 1s ease-out 0.3s both;
        }

        .title-slide .author {
            font-size: 1.2em;
            opacity: 0.8;
            animation: fadeIn 1s ease-out 0.6s both;
        }

        /* Layout 2: Enhanced Title and Content */
        .title-content h2 {
            font-size: 2.2em;
            color: #1E293B;
            margin-bottom: 30px;
            padding-bottom: 10px;
            border-bottom: 3px solid #EA580C;
            position: relative;
            overflow: hidden;
        }

        .title-content h2::after {
            content: '';
            position: absolute;
            bottom: -3px;
            left: -100%;
            width: 100%;
            height: 3px;
            background: #059669;
            transition: left 0.8s ease;
        }

        .title-content.visible h2::after {
            left: 0;
        }

        .content-area {
            font-size: 1.1em;
            line-height: 1.8;
        }

        .content-list {
            list-style: none;
            padding-left: 0;
        }

        .content-list li {
            position: relative;
            padding-left: 30px;
            margin-bottom: 15px;
            opacity: 0;
            transform: translateX(-20px);
            transition: all 0.6s ease;
        }

        .visible .content-list li {
            opacity: 1;
            transform: translateX(0);
        }

        .content-list li:nth-child(1) { transition-delay: 0.1s; }
        .content-list li:nth-child(2) { transition-delay: 0.2s; }
        .content-list li:nth-child(3) { transition-delay: 0.3s; }
        .content-list li:nth-child(4) { transition-delay: 0.4s; }
        .content-list li:nth-child(5) { transition-delay: 0.5s; }
        .content-list li:nth-child(6) { transition-delay: 0.6s; }

        .content-list li::before {
            content: "→";
            position: absolute;
            left: 0;
            color: #EA580C;
            font-weight: bold;
            font-size: 1.2em;
            transition: all 0.3s ease;
        }

        .content-list li:hover::before {
            color: #059669;
            transform: translateX(5px);
        }

        /* Layout 3: Enhanced Section Header */
        .section-header {
            background: linear-gradient(135deg, #059669, #EA580C);
            color: #FEF7ED;
            text-align: center;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            position: relative;
            overflow: hidden;
        }

        .section-header::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
            transition: left 0.8s ease;
        }

        .section-header.visible::before {
            left: 100%;
        }

        .section-header h1 {
            font-size: 3em;
            margin-bottom: 20px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .section-header .section-subtitle {
            font-size: 1.4em;
            opacity: 0.9;
        }

        /* Layout 4: Enhanced Two Content */
        .two-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            align-items: start;
        }

        .two-content h2 {
            grid-column: 1 / -1;
            font-size: 2.2em;
            color: #1E293B;
            margin-bottom: 30px;
            padding-bottom: 10px;
            border-bottom: 3px solid #EA580C;
        }

        .content-column {
            padding: 20px;
            background: rgba(5, 150, 105, 0.05);
            border-radius: 10px;
            transition: all 0.4s ease;
            transform: scale(0.95);
            opacity: 0;
        }

        .visible .content-column {
            transform: scale(1);
            opacity: 1;
        }

        .visible .content-column:nth-child(2) { transition-delay: 0.1s; }
        .visible .content-column:nth-child(3) { transition-delay: 0.2s; }

        .content-column:hover {
            background: rgba(5, 150, 105, 0.1);
            transform: scale(1.02);
            box-shadow: 0 8px 20px rgba(0,0,0,0.1);
        }

        .content-column h3 {
            font-size: 1.6em;
            color: #059669;
            margin-bottom: 15px;
            position: relative;
        }

        /* Layout 5: Enhanced Comparison */
        .comparison h2 {
            font-size: 2.2em;
            color: #1E293B;
            margin-bottom: 30px;
            padding-bottom: 10px;
            border-bottom: 3px solid #EA580C;
            text-align: center;
        }

        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            margin-top: 40px;
        }

        .comparison-item {
            text-align: center;
            padding: 30px;
            border-radius: 15px;
            background: rgba(234, 88, 12, 0.1);
            transition: all 0.5s ease;
            position: relative;
            overflow: hidden;
        }

        .comparison-item h3 {
            font-size: 1.8em;
            color: #EA580C;
            margin-bottom: 20px;
        }

        .vs-divider {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            background: #EA580C;
            color: #FEF7ED;
            padding: 10px 20px;
            border-radius: 50px;
            font-weight: bold;
            font-size: 1.2em;
            animation: pulse 2s ease-in-out infinite;
            box-shadow: 0 4px 15px rgba(234, 88, 12, 0.3);
        }

        .comparison {
            position: relative;
        }

        /* Layout 6: Enhanced Title Only */
        .title-only {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
        }

        .title-only h1 {
            font-size: 3em;
            color: #1E293B;
            margin-bottom: 20px;
            position: relative;
        }

        .title-only h1::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 50%;
            transform: translateX(-50%);
            width: 0;
            height: 3px;
            background: #EA580C;
            transition: width 0.8s ease;
        }

        .title-only.visible h1::after {
            width: 100%;
        }

        .title-only .subtitle {
            font-size: 1.4em;
            color: #059669;
            font-style: italic;
        }

        /* Interactive Quiz Layout */
        .interactive-quiz {
            background: rgba(5, 150, 105, 0.05);
            border-left: 5px solid #059669;
        }

        .interactive-quiz h2 {
            color: #059669;
            border-bottom-color: #059669;
        }

        .quiz-question {
            background: #FEF7ED;
            padding: 25px;
            margin: 20px 0;
            border-radius: 10px;
            border: 2px solid #059669;
            font-size: 1.2em;
        }

        .quiz-options {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin: 20px 0;
        }

        .quiz-option {
            padding: 15px;
            background: rgba(234, 88, 12, 0.1);
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }

        .quiz-option:hover {
            background: rgba(234, 88, 12, 0.2);
            border-color: #EA580C;
            transform: translateY(-2px);
        }

        .reveal-button {
            background: #EA580C;
            color: #FEF7ED;
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            font-size: 1.1em;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 20px 0;
        }

        .reveal-button:hover {
            background: #059669;
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(5, 150, 105, 0.3);
        }

        .quiz-answer {
            background: rgba(5, 150, 105, 0.1);
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #059669;
            margin-top: 20px;
            transform: translateY(-10px);
            opacity: 0;
            transition: all 0.5s ease;
        }

        .quiz-answer.visible {
            transform: translateY(0);
            opacity: 1;
        }

        /* Progressive Concept Layout */
        .progressive-concept {
            background: linear-gradient(to right, rgba(5, 150, 105, 0.05), rgba(234, 88, 12, 0.05));
        }

        .concept-steps {
            display: grid;
            gap: 30px;
            margin: 30px 0;
        }

        .concept-step {
            display: grid;
            grid-template-columns: 60px 1fr;
            gap: 20px;
            align-items: center;
            padding: 20px;
            background: #FEF7ED;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05);
            transform: translateX(-50px);
            opacity: 0;
            transition: all 0.6s ease;
        }

        .visible .concept-step {
            transform: translateX(0);
            opacity: 1;
        }

        .concept-step:nth-child(1) { transition-delay: 0.1s; }
        .concept-step:nth-child(2) { transition-delay: 0.2s; }
        .concept-step:nth-child(3) { transition-delay: 0.3s; }
        .concept-step:nth-child(4) { transition-delay: 0.4s; }
        .concept-step:nth-child(5) { transition-delay: 0.5s; }

        .step-number {
            width: 50px;
            height: 50px;
            background: #EA580C;
            color: #FEF7ED;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 1.2em;
        }

        .step-content h4 {
            color: #059669;
            margin-bottom: 10px;
            font-size: 1.3em;
        }

        /* Visual Metaphor Layout */
        .visual-metaphor {
            display: grid;
            grid-template-columns: 1.5fr 1fr;
            gap: 40px;
            align-items: start;
        }

        .metaphor-visual {
            position: relative;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
        }

        .metaphor-explanation {
            background: rgba(5, 150, 105, 0.05);
            padding: 30px;
            border-radius: 15px;
            border-left: 5px solid #059669;
        }

        .metaphor-explanation h3 {
            color: #059669;
            margin-bottom: 20px;
            font-size: 1.6em;
        }

        .metaphor-connection {
            background: rgba(234, 88, 12, 0.1);
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
            border-left: 4px solid #EA580C;
        }

        /* Special Elements */
        .highlight-box {
            background: #059669;
            color: #FEF7ED;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-weight: bold;
            position: relative;
            overflow: hidden;
        }

        .accent-box {
            background: #EA580C;
            color: #FEF7ED;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            font-style: italic;
            transform: scale(0.98);
            transition: all 0.3s ease;
        }

        .accent-box:hover {
            transform: scale(1);
            box-shadow: 0 8px 20px rgba(234, 88, 12, 0.3);
        }

        .emphasis {
            background: #EA580C;
            color: #FEF7ED;
            padding: 4px 8px;
            border-radius: 5px;
            font-weight: bold;
            display: inline-block;
            transition: all 0.3s ease;
        }

        .emphasis:hover {
            background: #059669;
            transform: scale(1.05);
        }

        /* Algorithm Visualization */
        .algorithm-viz {
            background: rgba(30, 41, 59, 0.05);
            border: 2px solid #1E293B;
            border-radius: 15px;
            padding: 30px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            position: relative;
        }

        .algorithm-step {
            padding: 10px;
            margin: 5px 0;
            background: rgba(5, 150, 105, 0.1);
            border-left: 4px solid #059669;
            border-radius: 5px;
            transition: all 0.3s ease;
        }

        .algorithm-step:hover {
            background: rgba(5, 150, 105, 0.2);
            transform: translateX(5px);
        }

        /* Animations */
        @keyframes slideInFromTop {
            from {
                opacity: 0;
                transform: translateY(-50px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes slideInFromLeft {
            from {
                opacity: 0;
                transform: translateX(-50px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }
            to {
                opacity: 1;
            }
        }

        @keyframes float {
            0%, 100% {
                transform: rotate(0deg);
            }
            50% {
                transform: rotate(180deg);
            }
        }

        @keyframes pulse {
            0%, 100% {
                transform: translate(-50%, -50%) scale(1);
            }
            50% {
                transform: translate(-50%, -50%) scale(1.05);
            }
        }

        @keyframes bounce {
            0%, 100% {
                transform: translateY(0);
            }
            50% {
                transform: translateY(-20px);
            }
        }

        /* Navigation */
        .slide-counter {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: #1E293B;
            color: #FEF7ED;
            padding: 12px 18px;
            border-radius: 25px;
            font-size: 0.9em;
            box-shadow: 0 4px 15px rgba(30, 41, 59, 0.3);
            transition: all 0.3s ease;
            z-index: 1000;
        }

        .slide-counter:hover {
            background: #EA580C;
            transform: scale(1.05);
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }

            .slide {
                padding: 20px;
                min-height: 400px;
            }

            .title-slide h1 {
                font-size: 2.5em;
            }

            .two-content,
            .comparison-grid,
            .visual-metaphor {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .quiz-options {
                grid-template-columns: 1fr;
            }

            .vs-divider {
                display: none;
            }

            .concept-step {
                grid-template-columns: 50px 1fr;
                gap: 15px;
            }

            .step-number {
                width: 40px;
                height: 40px;
                font-size: 1em;
            }
        }
    </style>
</head>
<body>
    <!-- Progress Bar -->
    <div class="progress-bar" id="progressBar"></div>

    <div class="container">
        
        <!-- Title Slide -->
        <div class="slide title-slide">
            <h1>🔍 Local Search & Optimization</h1>
            <p class="subtitle">From Hill Climbing to Finding Global Solutions</p>
            <p class="author">Interactive AI Learning • Professor Claude</p>
        </div>

        <!-- What is Local Search? - Detailed Introduction -->
        <div class="slide title-content">
            <h2>🔍 What Exactly is Local Search?</h2>
            
            <div class="content-area">
                <p><strong>Local search</strong> is a fundamentally different approach to solving optimization problems. Unlike traditional search algorithms that maintain a frontier of unexplored nodes and systematically explore the entire search space, local search operates on a completely different principle.</p>
                
                <div class="highlight-box">
                    Local search algorithms operate using only a <strong>single current node</strong> (not multiple paths) and generally move only to <strong>neighbors</strong> of that node.
                </div>
                
                <h3>Key Characteristics:</h3>
                <ul class="content-list">
                    <li><strong>Single State Focus:</strong> Maintains only one current state at any time</li>
                    <li><strong>Neighborhood Exploration:</strong> Only considers states reachable in one step</li>
                    <li><strong>Path Irrelevant:</strong> Doesn't care how we got to current state, only where we are</li>
                    <li><strong>Memory Efficient:</strong> Uses constant space regardless of problem size</li>
                    <li><strong>Incomplete:</strong> May not find a solution even if one exists</li>
                    <li><strong>Fast:</strong> Can find reasonable solutions quickly for large problems</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Real-World Applications:</strong> VLSI design, job scheduling, neural network training, traveling salesman problem, facility location, and many AI optimization tasks where finding a "good enough" solution quickly is more valuable than guaranteeing the optimal solution.
                </div>
            </div>
        </div>

        <!-- Local Search Advantages and Use Cases -->
        <div class="slide title-content">
            <h2>🏔️ Why Use Local Search? The Mountain Climbing Analogy</h2>
            
            <div class="content-area">
                <p>Imagine you're a hiker trying to reach the highest point in a mountain range, but you're caught in thick fog that limits your visibility to just nearby terrain. This perfectly captures the essence of local search.</p>
                
                <h3>The Fog Analogy Explained:</h3>
                <ul class="content-list">
                    <li><strong>Limited Visibility:</strong> You can only see immediate neighbors (one-step moves)</li>
                    <li><strong>No Global Map:</strong> No complete knowledge of the entire landscape</li>
                    <li><strong>Greedy Decisions:</strong> Always move to the highest visible point</li>
                    <li><strong>Local Information:</strong> Make decisions based only on current surroundings</li>
                    <li><strong>Risk of Local Peaks:</strong> Might reach a hill that's not the highest mountain</li>
                </ul>
                
                <div class="highlight-box">
                    <strong>Key Insight:</strong> Sometimes we don't need the path to the solution - we just need to find the best state itself! The journey doesn't matter, only the destination.
                </div>
                
                <h3>When to Choose Local Search:</h3>
                <ul class="content-list">
                    <li><strong>Large State Spaces:</strong> When systematic search would take too long</li>
                    <li><strong>Optimization Problems:</strong> Finding best configuration rather than path</li>
                    <li><strong>Continuous Spaces:</strong> Infinite or near-infinite search spaces</li>
                    <li><strong>Time Constraints:</strong> Need reasonable solution quickly</li>
                    <li><strong>Memory Limitations:</strong> Cannot store large search trees</li>
                </ul>
            </div>
        </div>

        <!-- Detailed Path vs State Optimization -->
        <div class="slide comparison">
            <h2>🎯 Path-Finding vs. State Optimization: A Deep Dive</h2>
            
            <div class="comparison-grid">
                <div class="comparison-item">
                    <h3>Path-Based Search</h3>
                    <p><strong>Goal:</strong> Find the sequence of actions to reach a goal state</p>
                    
                    <div class="highlight-box">
                        "How do I get from A to B?"
                    </div>
                    
                    <p><strong>Examples:</strong></p>
                    <ul class="content-list">
                        <li><strong>GPS Navigation:</strong> Find route from home to work</li>
                        <li><strong>Puzzle Solving:</strong> Steps to solve Rubik's cube</li>
                        <li><strong>Game Playing:</strong> Move sequence to win chess</li>
                        <li><strong>Robot Planning:</strong> Actions to reach target location</li>
                    </ul>
                    
                    <p><strong>What Matters:</strong> The sequence of moves, total cost of path, optimality of route</p>
                </div>
                
                <div class="comparison-item">
                    <h3>State Optimization</h3>
                    <p><strong>Goal:</strong> Find the best possible arrangement or configuration</p>
                    
                    <div class="accent-box">
                        "What's the best arrangement?"
                    </div>
                    
                    <p><strong>Examples:</strong></p>
                    <ul class="content-list">
                        <li><strong>8-Queens:</strong> Arrange queens so none attack</li>
                        <li><strong>Scheduling:</strong> Assign tasks to minimize completion time</li>
                        <li><strong>Circuit Design:</strong> Place components to minimize wire length</li>
                        <li><strong>Portfolio Optimization:</strong> Allocate investments for best return</li>
                    </ul>
                    
                    <p><strong>What Matters:</strong> The final configuration quality, not how we arrived there</p>
                </div>
            </div>
            
            <div class="vs-divider">VS</div>
        </div>

        <!-- Introduction to Optimization Problems -->
        <div class="slide title-content">
            <h2>📊 Understanding Optimization Problems</h2>
            
            <div class="content-area">
                <p>Before diving into local search algorithms, we need to understand how to convert problems into optimization format. This is crucial because local search works on <strong>objective functions</strong> rather than goal tests.</p>
                
                <h3>Components of an Optimization Problem:</h3>
                <ul class="content-list">
                    <li><strong>State Space:</strong> All possible configurations or solutions</li>
                    <li><strong>Objective Function:</strong> Maps each state to a numerical value</li>
                    <li><strong>Goal:</strong> Find state that maximizes (or minimizes) the objective function</li>
                    <li><strong>Constraints:</strong> Rules that valid solutions must satisfy</li>
                </ul>
                
                <div class="highlight-box">
                    <strong>Key Difference:</strong> Instead of asking "Is this a goal state?" we ask "How good is this state?"
                </div>
                
                <h3>Satisfaction vs. Optimization:</h3>
                <ul class="content-list">
                    <li><strong>Constraint Satisfaction:</strong> Find any valid solution (like solving sudoku)</li>
                    <li><strong>Constraint Optimization:</strong> Find the best valid solution (like best sudoku solution in minimum time)</li>
                    <li><strong>Pure Optimization:</strong> All states are valid, just find the best one</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Converting Problems:</strong> Many satisfaction problems can be converted to optimization by defining how many constraints are violated (minimize violations) or how many are satisfied (maximize satisfaction).
                </div>
            </div>
        </div>

        <!-- Section: Basic Hill Climbing -->
        <div class="slide section-header">
            <h1>⛰️ Hill Climbing Algorithm</h1>
            <p class="section-subtitle">The Foundation of Local Search</p>
        </div>

        <!-- Hill Climbing: Detailed Algorithm -->
        <div class="slide progressive-concept">
            <h2>🥾 Hill Climbing: Step-by-Step Breakdown</h2>
            
            <p style="margin-bottom: 30px; font-size: 1.2em;">Hill climbing is the simplest and most intuitive local search algorithm. Think of it as a greedy algorithm that always takes the locally best step.</p>
            
            <div class="concept-steps">
                <div class="concept-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Initialize</h4>
                        <p><strong>Start with a random state</strong> or use problem-specific heuristics to choose a good starting point. This initial state becomes your "current" state.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Generate Neighbors</h4>
                        <p><strong>Find all neighboring states</strong> - states reachable by one legal move. The definition of "neighbor" depends on your problem domain.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Evaluate All Neighbors</h4>
                        <p><strong>Calculate objective function value</strong> for each neighbor. This tells us how "good" each potential move is.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Select Best Neighbor</h4>
                        <p><strong>Choose the neighbor with the best value</strong> (highest for maximization, lowest for minimization). If there are ties, choose randomly among the best.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>Check Termination</h4>
                        <p><strong>If no neighbor is better than current state, STOP</strong> - you've reached a local optimum. Otherwise, move to the best neighbor and repeat from step 2.</p>
                    </div>
                </div>
            </div>
            
            <div class="algorithm-viz">
                <div class="algorithm-step"><strong>function</strong> HILL-CLIMBING(problem):</div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;current ← MAKE-NODE(INITIAL-STATE[problem])</div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;<strong>loop do</strong></div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;neighbor ← highest-valued successor of current</div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>if</strong> VALUE[neighbor] ≤ VALUE[current] <strong>then</strong></div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>return</strong> STATE[current]</div>
                <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;current ← neighbor</div>
            </div>
        </div>

        <!-- N-Queens Introduction -->
        <div class="slide title-content">
            <h2>♛ Understanding the N-Queens Problem</h2>
            
            <div class="content-area">
                <p>The N-Queens problem is a classic puzzle that perfectly demonstrates local search concepts. Let's start with the simpler 4-Queens version to understand the fundamentals.</p>
                
                <div class="image-container">
                    <img src="images/ai/nqueens-initial-state.png" alt="N-Queens problem initial state showing 8 queens placed on a chessboard with string representation 16257483" />
                </div>
                
                <h3>Problem Definition:</h3>
                <ul class="content-list">
                    <li><strong>Goal:</strong> Place N queens on an N×N chessboard</li>
                    <li><strong>Constraint:</strong> No two queens can attack each other</li>
                    <li><strong>Attack Rules:</strong> Queens attack along rows, columns, and diagonals</li>
                    <li><strong>Solution:</strong> Any valid arrangement satisfying all constraints</li>
                </ul>
                
                <div class="highlight-box">
                    <strong>Why Start with N-Queens?</strong> The N×N board is complex enough to demonstrate the key concepts of local search while being visualizable and understandable.
                </div>
                
                <h3>Understanding Queen Attacks:</h3>
                <ul class="content-list">
                    <li><strong>Horizontal:</strong> Queens attack all squares in their row</li>
                    <li><strong>Vertical:</strong> Queens attack all squares in their column</li>
                    <li><strong>Diagonal:</strong> Queens attack along both diagonal directions</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Key Insight:</strong> For N-Queens, we need exactly N queens placed such that each row, column, and diagonal contains at most one queen. The string representation shows queen positions as "16257483" where each position indicates the row of the queen in that column.
                </div>
            </div>
        </div>

        <!-- 8-Queens: Converting to Optimization -->
        <div class="slide title-content">
            <h2>♛ The 8-Queens Problem: Optimization Approach</h2>
            
            <div class="content-area">
                <p>Now let's scale up to the classic 8-Queens problem and see how we convert this constraint satisfaction problem into an optimization problem suitable for local search.</p>
                
                <div class="image-container">
                    <img src="images/ai/Hill_climb_calculate.jpg" alt="8-Queens problem with heuristic calculations" />
                </div>
                
                <div class="highlight-box">
                    <strong>Converting to Optimization Problem:</strong> Instead of finding any valid solution, we minimize the number of constraint violations.
                </div>
                
                <h3>Optimization Formulation:</h3>
                <ul class="content-list">
                    <li><strong>State:</strong> All 8 queens placed on the board (one per column)</li>
                    <li><strong>Objective Function h(n):</strong> Number of pairs of queens attacking each other</li>
                    <li><strong>Goal:</strong> Minimize h(n) to reach h = 0 (perfect solution)</li>
                    <li><strong>Neighbor Definition:</strong> Move one queen to different row in same column</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Example:</strong> In the shown configuration, h = 17 attacking pairs. Our goal is to find moves that reduce this number, ideally to h = 0.
                </div>
                
                <h3>Why This Formulation Works:</h3>
                <ul class="content-list">
                    <li><strong>Measurable Progress:</strong> Each move can be evaluated numerically</li>
                    <li><strong>Local Improvements:</strong> Can make greedy decisions based on h-value</li>
                    <li><strong>Clear Termination:</strong> h = 0 means we found a solution</li>
                    <li><strong>Neighbor Generation:</strong> Easy to generate all possible single-queen moves</li>
                </ul>
                
                <p><strong>State Representation:</strong> We can represent each state as a string like "24748552" where position i contains the row number of the queen in column i.</p>
            </div>
        </div>

        <!-- Detailed Hill Climbing Example -->
        <div class="slide title-content">
            <h2>🔢 Hill Climbing on 8-Queens: Detailed Example</h2>
            
            <div class="content-area">
                <p>Let's walk through exactly how hill climbing works on the 8-Queens problem, step by step.</p>
                
                <h3>Starting Configuration Analysis:</h3>
                <p>Looking at our initial state with h = 17 attacking pairs:</p>
                
                <ul class="content-list">
                    <li><strong>Row Conflicts:</strong> Count queens in same row</li>
                    <li><strong>Diagonal Conflicts:</strong> Count queens on same diagonal</li>
                    <li><strong>Total Conflicts:</strong> Sum all attacking pairs</li>
                </ul>
                
                <div class="highlight-box">
                    <strong>Neighbor Generation:</strong> For each of the 8 queens, we can move it to any of the other 7 positions in its column. This gives us 8 × 7 = 56 possible neighbors.
                </div>
                
                <h3>Evaluation Process:</h3>
                <ul class="content-list">
                    <li><strong>For each neighbor:</strong> Calculate new h-value</li>
                    <li><strong>Compare values:</strong> Find minimum h among all neighbors</li>
                    <li><strong>Make move:</strong> If best neighbor is better than current, move there</li>
                    <li><strong>Repeat:</strong> Continue until no improvement possible</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Computational Efficiency:</strong> We don't need to recalculate h from scratch each time. When moving one queen, we can incrementally update the conflict count by considering only the affected pairs.
                </div>
                
                <h3>Typical Hill Climbing Trajectory:</h3>
                <p>Starting from h = 17, a typical run might progress: 17 → 12 → 8 → 5 → 3 → 2 → 1 → stuck at local minimum</p>
            </div>
        </div>

        <!-- Interactive Quiz -->
        <div class="slide interactive-quiz">
            <h2>🧠 Quick Check: Understanding Hill Climbing</h2>
            
            <div class="quiz-question">
                <strong>Question:</strong> You're using hill climbing on 8-Queens and reach a state where all 56 possible moves result in worse or equal h-values compared to your current state (h = 2). What has happened?
            </div>
            
            <div class="quiz-options">
                <div class="quiz-option">A) Found the global optimum (h = 0)</div>
                <div class="quiz-option">B) Reached a local minimum (stuck)</div>
                <div class="quiz-option">C) Made a computational error</div>
                <div class="quiz-option">D) Need to generate more neighbors</div>
            </div>
            
            <button class="reveal-button" onclick="revealAnswer('quiz1')">Reveal Answer</button>
            
            <div class="quiz-answer" id="quiz1">
                <strong>Answer: B) Reached a local minimum (stuck)</strong><br>
                Hill climbing stops when no neighbor is better than the current state. With h = 2, we haven't reached the global optimum (h = 0), but we're stuck at a local minimum where all single-queen moves make things worse. This is exactly why basic hill climbing only succeeds 14% of the time on 8-Queens!
            </div>
        </div>

        <!-- Problems with Hill Climbing -->
        <div class="slide section-header">
            <h1>⚠️ When Hill Climbing Gets Stuck</h1>
            <p class="section-subtitle">Understanding the Fundamental Limitations</p>
        </div>

        <!-- Hill Climbing Problem Landscape Overview -->
        <div class="slide title-content">
            <h2>🗺️ The Hill Climbing Landscape: Understanding the Terrain</h2>
            
            <div class="content-area">
                <p>Before diving into specific problems, let's visualize the optimization landscape that hill climbing algorithms must navigate. This landscape metaphor helps us understand why local search can get stuck.</p>
                
                <div class="image-container">
                    <img src="images/ai/Hill_climb_landscape.jpg" alt="Hill climbing landscape showing global maximum, local maximum, shoulder, and current state with objective function plotted against state space" />
                </div>
                
                <div class="highlight-box">
                    <strong>Key Landscape Features:</strong> The search space contains peaks (local maxima), flat areas (plateaus/shoulders), and valleys that create challenges for local search algorithms.
                </div>
                
                <h3>Understanding the Terrain:</h3>
                <ul class="content-list">
                    <li><strong>Global Maximum:</strong> The highest peak - our ultimate goal</li>
                    <li><strong>Local Maximum:</strong> Smaller peaks that can trap the algorithm</li>
                    <li><strong>Shoulder:</strong> Flat areas that extend from peaks</li>
                    <li><strong>Current State:</strong> Where our algorithm is currently positioned</li>
                    <li><strong>State Space:</strong> All possible configurations we can explore</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Navigation Challenge:</strong> Hill climbing can only see immediate neighbors, like navigating in thick fog where visibility is limited to just a few steps in any direction.
                </div>
            </div>
        </div>

        <!-- Local Maxima Problem -->
        <div class="slide two-content">
            <h2>🏔️ Problem 1: Local Maxima</h2>
            
            <div class="content-column">
                <div class="image-container">
                    <img src="images/ai/Hill_climb_error.jpg" alt="Hill climbing getting stuck at local maximum" />
                </div>
            </div>
            
            <div class="content-column">
                <h3>The Local Maximum Trap</h3>
                <p>A <strong>local maximum</strong> is a state that is better than all its neighbors, but not necessarily the best state in the entire search space.</p>
                
                <div class="highlight-box">
                    <strong>Analogy:</strong> Like reaching the top of a small hill when Mount Everest is nearby but hidden by fog.
                </div>
                
                <h3>Why This Happens:</h3>
                <ul class="content-list">
                    <li><strong>Limited Vision:</strong> Hill climbing only sees immediate neighbors</li>
                    <li><strong>Greedy Nature:</strong> Always takes the locally best step</li>
                    <li><strong>No Backtracking:</strong> Cannot undo previous moves</li>
                </ul>
                
                <h3>8-Queens Example:</h3>
                <p>Might get stuck at h = 1 (one attacking pair) where all single moves make things worse, even though h = 0 solutions exist.</p>
                
                <div class="accent-box">
                    <strong>Frequency:</strong> For 8-Queens, basic hill climbing gets stuck in local maxima about 86% of the time!
                </div>
            </div>
        </div>

        <!-- Plateaus Problem -->
        <div class="slide two-content">
            <h2>🏔️ Problem 2: Plateaus (Flat Areas)</h2>
            
            <div class="content-column">
                <div class="image-container">
                    <img src="images/ai/Hill_climb_problems_combined.jpg" alt="Search landscape showing all three types of problems: local maxima, plateaus with shoulders, and ridges that create challenges for hill climbing algorithms" />
                </div>
            </div>
            
            <div class="content-column">
                <h3>The Plateau Problem</h3>
                <p>A <strong>plateau</strong> is a flat area of the search space where all neighboring states have the same objective function value.</p>
                
                <div class="highlight-box">
                    <strong>Analogy:</strong> Like walking on a flat mesa where every direction looks the same height.
                </div>
                
                <h3>Two Types of Plateaus:</h3>
                <ul class="content-list">
                    <li><strong>Flat Local Maximum:</strong> Flat area that is a local optimum</li>
                    <li><strong>Shoulder:</strong> Flat area with better regions beyond it</li>
                </ul>
                
                <h3>The Challenge:</h3>
                <p>Standard hill climbing stops because no neighbor is <em>better</em>, but progress might be possible by moving to equally good states.</p>
                
                <div class="accent-box">
                    <strong>Solution Preview:</strong> Allow "sideways moves" to states with equal value, but limit the number to avoid infinite loops.
                </div>
                
                <h3>All Three Problems Visualized:</h3>
                <p>The image shows how local maxima, plateaus, and ridges all create different types of traps for hill climbing algorithms in the optimization landscape.</p>
            </div>
        </div>

        <!-- Ridges Problem -->
        <div class="slide title-content">
            <h2>🏔️ Problem 3: Ridges and Diagonal Movement</h2>
            
            <div class="content-area">
                <p>A <strong>ridge</strong> is a long, narrow area of high values with steep sides. The challenge is that progress along the ridge requires diagonal movement, but hill climbing can only move to direct neighbors.</p>
                
                <div class="highlight-box">
                    <strong>Analogy:</strong> Like trying to walk along a narrow mountain ridge when you can only move north, south, east, or west - but the ridge runs northeast to southwest.
                </div>
                
                <h3>Why Ridges Are Problematic:</h3>
                <ul class="content-list">
                    <li><strong>Limited Move Set:</strong> Can only make moves defined by neighbor function</li>
                    <li><strong>Steep Sides:</strong> Any single step off the ridge leads to much worse states</li>
                    <li><strong>Diagonal Progress:</strong> Optimal path requires coordinated multi-variable changes</li>
                    <li><strong>Local Optima Chain:</strong> May get stuck at any point along the ridge</li>
                </ul>
                
                <h3>Real-World Example:</h3>
                <p>In neural network training, the loss function often has ridges where optimal progress requires adjusting multiple weights simultaneously, but gradient descent adjusts one dimension at a time.</p>
                
                <div class="accent-box">
                    <strong>Ridge Navigation:</strong> Advanced techniques like simulated annealing or genetic algorithms can better handle ridges by allowing coordinated multi-dimensional moves or accepting temporary downhill moves.
                </div>
                
                <h3>8-Queens and Ridges:</h3>
                <p>Ridges are less common in 8-Queens because the discrete nature of the problem and the neighbor definition, but they can occur in continuous optimization problems or problems with more complex neighbor relationships.</p>
            </div>
        </div>

        <!-- Hill Climbing Performance Analysis -->
        <div class="slide title-content">
            <h2>📊 Hill Climbing Performance: The Numbers</h2>
            
            <div class="content-area">
                <p>Let's examine the empirical performance of hill climbing on the 8-Queens problem to understand its strengths and limitations.</p>
                
                <div class="highlight-box">
                    <strong>Experimental Setup:</strong> Run hill climbing from many random starting states and measure success rate and steps to solution.
                </div>
                
                <h3>8-Queens Performance Statistics:</h3>
                <ul class="content-list">
                    <li><strong>Success Rate:</strong> 14% (finds solution h = 0)</li>
                    <li><strong>Failure Rate:</strong> 86% (gets stuck at local minimum)</li>
                    <li><strong>Steps When Successful:</strong> Average of 4 steps</li>
                    <li><strong>Steps When Stuck:</strong> Average of 3 steps</li>
                    <li><strong>Search Space Size:</strong> 8^8 ≈ 16.7 million possible states</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Remarkable Efficiency:</strong> When hill climbing works, it finds solutions incredibly quickly - just 4 steps on average in a space of 16 million states!
                </div>
                
                <h3>What These Numbers Tell Us:</h3>
                <ul class="content-list">
                    <li><strong>Fast Convergence:</strong> Algorithm terminates very quickly (good or bad)</li>
                    <li><strong>High Failure Rate:</strong> Most random starts lead to local optima</li>
                    <li><strong>Predictable Failure:</strong> Usually fails within a few steps</li>
                    <li><strong>Memory Efficient:</strong> Uses O(1) space regardless of search space size</li>
                </ul>
                
                <p><strong>Trade-off Analysis:</strong> Hill climbing trades completeness (guaranteed solution finding) for speed and memory efficiency. This trade-off is often worthwhile in real-world applications where "good enough" solutions are acceptable.</p>
            </div>
        </div>

        <!-- Solutions Section -->
        <div class="slide section-header">
            <h1>🔧 Smart Solutions to Hill Climbing Problems</h1>
            <p class="section-subtitle">Escaping Local Optima</p>
        </div>

        <!-- Sideways Moves Solution -->
        <div class="slide title-content">
            <h2>↔️ Solution 1: Allowing Sideways Moves</h2>
            
            <div class="content-area">
                <p>The simplest modification to basic hill climbing is to allow <strong>sideways moves</strong> - moves to neighbors with equal objective function values. This helps escape plateaus and shoulders.</p>
                
                <div class="highlight-box">
                    <strong>Key Modification:</strong> Instead of stopping when no neighbor is strictly better, continue moving to equally good neighbors.
                </div>
                
                <h3>Algorithm Modification:</h3>
                <div class="algorithm-viz">
                    <div class="algorithm-step"><strong>if</strong> VALUE[neighbor] ≤ VALUE[current] <strong>then</strong></div>
                    <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;<em>// Original: stop here</em></div>
                    <div class="algorithm-step"><strong>if</strong> VALUE[neighbor] &lt; VALUE[current] <strong>then</strong></div>
                    <div class="algorithm-step">&nbsp;&nbsp;&nbsp;&nbsp;<em>// Modified: only stop if strictly worse</em></div>
                </div>
                
                <h3>The Infinite Loop Problem:</h3>
                <ul class="content-list">
                    <li><strong>Issue:</strong> Might move in circles on flat areas</li>
                    <li><strong>Solution:</strong> Limit the number of consecutive sideways moves</li>
                    <li><strong>Typical Limit:</strong> 100 sideways moves before giving up</li>
                </ul>
                
                <div class="accent-box">
                    <strong>8-Queens Results with Sideways Moves:</strong><br>
                    • Success rate increases from <span class="emphasis">14% to 94%</span><br>
                    • Average steps for success: <span class="emphasis">21 steps</span><br>
                    • Average steps for failure: <span class="emphasis">64 steps</span>
                </div>
                
                <h3>Trade-offs:</h3>
                <ul class="content-list">
                    <li><strong>Pro:</strong> Dramatically improved success rate</li>
                    <li><strong>Con:</strong> Takes longer to run (more steps per attempt)</li>
                    <li><strong>Pro:</strong> Still very fast compared to systematic search</li>
                    <li><strong>Con:</strong> Still gets stuck at local maxima (6% of the time)</li>
                </ul>
            </div>
        </div>

        <!-- Random Restarts Solution -->
        <div class="slide progressive-concept">
            <h2>🎲 Solution 2: Hill Climbing with Random Restarts</h2>
            
            <p style="margin-bottom: 30px; font-size: 1.2em;"><strong>"If at first you don't succeed, try, try again!"</strong> This is the most practical and widely-used enhancement to hill climbing.</p>
            
            <div class="concept-steps">
                <div class="concept-step">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>Run Basic Hill Climbing</h4>
                        <p>Start from a random initial state and run hill climbing until it terminates (either finds solution or gets stuck).</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>Check Success</h4>
                        <p>If hill climbing found a satisfactory solution, return it and stop. Otherwise, record the best solution found so far.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>Generate New Random Start</h4>
                        <p>Create a completely new random initial state, independent of previous attempts. This gives us a fresh perspective on the search space.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>Repeat Process</h4>
                        <p>Go back to step 1 and repeat the entire process. Continue until finding a solution or reaching a time/iteration limit.</p>
                    </div>
                </div>
            </div>
            
            <div class="highlight-box">
                <strong>Key Insight:</strong> Different starting points lead to different local optima. By trying many starts, we eventually find one that leads to the global optimum.
            </div>
            
            <div class="accent-box">
                <strong>Mathematical Analysis:</strong> If each restart has probability <span class="emphasis">p</span> of success:<br>
                • Expected number of restarts: <span class="emphasis">1/p</span><br>
                • For 8-Queens with p = 0.14: Expected <span class="emphasis">≈ 7 restarts</span><br>
                • Total expected steps: <span class="emphasis">7 × 4 = 28 steps</span>
            </div>
        </div>

        <!-- Random Walk Solution -->
        <div class="slide two-content">
            <h2>🚶 Solution 3: Hill Climbing with Random Walk</h2>
            
            <div class="content-column">
                <h3>The Completeness Problem</h3>
                <p>Pure hill climbing can never be <strong>complete</strong> (guaranteed to find a solution if one exists) because it can get permanently stuck in local optima.</p>
                
                <div class="highlight-box">
                    Random walk, on the other hand, is <strong>asymptotically complete</strong> - given infinite time, it will eventually find any reachable solution.
                </div>
                
                <h3>The Key Insight:</h3>
                <p>Combine the efficiency of greedy hill climbing with the completeness of random exploration.</p>
            </div>
            
            <div class="content-column">
                <h3>The Hybrid Algorithm</h3>
                <p><strong>At each step, make a probabilistic choice:</strong></p>
                
                <ul class="content-list">
                    <li><strong>With probability p:</strong> Make greedy move to best neighbor (exploitation)</li>
                    <li><strong>With probability (1-p):</strong> Move to a randomly chosen neighbor (exploration)</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Parameter Tuning:</strong><br>
                    • High p (e.g., 0.8): Mostly greedy, fast convergence<br>
                    • Low p (e.g., 0.3): More exploration, better escape from local optima
                </div>
                
                <h3>Benefits:</h3>
                <ul class="content-list">
                    <li><strong>Escape Mechanism:</strong> Random moves can escape local optima</li>
                    <li><strong>Maintains Progress:</strong> Greedy moves still drive toward better solutions</li>
                    <li><strong>Tunable Balance:</strong> Can adjust exploration vs. exploitation</li>
                </ul>
            </div>
        </div>

        <!-- Stochastic Variations -->
        <div class="slide title-content">
            <h2>🎯 Solution 4: Stochastic Hill Climbing Variations</h2>
            
            <div class="content-area">
                <p>Instead of always choosing the single best neighbor, stochastic variations introduce randomness in the selection process while still biasing toward better moves.</p>
                
                <h3>Three Main Stochastic Approaches:</h3>
                
                <div class="highlight-box">
                    <strong>1. Stochastic Hill Climbing</strong><br>
                    Instead of choosing the absolute best neighbor, randomly select among the uphill moves, with probability proportional to the steepness of each move.
                </div>
                
                <p><strong>How it works:</strong> If we have neighbors with improvements of +2, +5, and +1, we might select them with probabilities 2/8, 5/8, and 1/8 respectively.</p>
                
                <div class="highlight-box">
                    <strong>2. First-Choice Hill Climbing</strong><br>
                    Generate neighbors randomly (rather than systematically) and choose the first one that is better than the current state.
                </div>
                
                <p><strong>Advantage:</strong> Useful when the number of neighbors is very large, as we don't need to evaluate all of them.</p>
                
                <div class="highlight-box">
                    <strong>3. Random-Restart Random Walk Hill Climbing</strong><br>
                    Combine all techniques: at each step, choose between greedy move, random move, or random restart.
                </div>
                
                <div class="accent-box">
                    <strong>Advanced Variation - Tabu Search:</strong> Keep a "tabu list" of recently visited states and forbid returning to them. This prevents cycles and encourages exploration of new areas.
                </div>
                
                <h3>Performance Considerations:</h3>
                <ul class="content-list">
                    <li><strong>Diversification:</strong> Stochastic selection explores more of the search space</li>
                    <li><strong>Robustness:</strong> Less likely to get trapped by single bad decision</li>
                    <li><strong>Parameter Sensitivity:</strong> Performance depends on random number generation and probability distributions</li>
                </ul>
            </div>
        </div>

        <!-- Simulated Annealing: Detailed Explanation -->
        <div class="slide visual-metaphor">
            <h2 style="grid-column: 1 / -1; font-size: 2.2em; color: #1E293B; margin-bottom: 30px; padding-bottom: 10px; border-bottom: 3px solid #EA580C;">🔥 Simulated Annealing: Physics-Inspired Search</h2>
            
            <div class="metaphor-visual">
                <div class="image-container">
                    <div style="background: linear-gradient(45deg, #FF6B6B, #4ECDC4, #45B7D1); color: #FEF7ED; padding: 80px; text-align: center; font-size: 1.5em; font-weight: bold; border-radius: 10px;">
                        🌡️ Cooling Metal to Perfect Crystal Structure
                    </div>
                </div>
            </div>
            
            <div class="metaphor-explanation">
                <h3>The Metallurgy Inspiration</h3>
                <p>Simulated annealing mimics the physical process of annealing in metallurgy - slowly cooling molten metal to form perfect crystal structures.</p>
                
                <h3>Physical Process:</h3>
                <ul class="content-list">
                    <li><strong>High Temperature:</strong> Atoms move randomly, high energy</li>
                    <li><strong>Gradual Cooling:</strong> Atoms settle into lower energy states</li>
                    <li><strong>Slow Cooling:</strong> Allows time to find global minimum energy</li>
                    <li><strong>Fast Cooling:</strong> Gets trapped in suboptimal crystal structure</li>
                </ul>
                
                <div class="metaphor-connection">
                    <strong>Search Algorithm Mapping:</strong><br>
                    • <strong>Energy → Objective Function:</strong> Lower energy = better solution<br>
                    • <strong>Temperature → Randomness:</strong> Higher temp = more random moves<br>
                    • <strong>Cooling → Time:</strong> Gradually reduce randomness over time
                </div>
            </div>
        </div>

        <!-- Simulated Annealing Algorithm Details -->
        <div class="slide title-content">
            <h2>🌡️ Simulated Annealing: Mathematical Foundation</h2>
            
            <div class="content-area">
                <p>Simulated annealing extends hill climbing by occasionally accepting moves that worsen the objective function, with the probability of acceptance decreasing over time.</p>
                
                <div class="highlight-box">
                    <strong>Core Idea:</strong> Accept bad moves early (high temperature) to escape local optima, then become increasingly greedy (low temperature) to converge to optimum.
                </div>
                
                <h3>The Acceptance Probability Formula:</h3>
                <div class="algorithm-viz">
                    <div class="algorithm-step">P(accept worse move) = e^(ΔE/T)</div>
                    <div class="algorithm-step">where:</div>
                    <div class="algorithm-step">• ΔE = change in objective function (negative for worse moves)</div>
                    <div class="algorithm-step">• T = current temperature (positive)</div>
                </div>
                
                <h3>Understanding the Formula:</h3>
                <ul class="content-list">
                    <li><strong>ΔE > 0:</strong> Better move → always accept (probability = 1)</li>
                    <li><strong>ΔE < 0:</strong> Worse move → accept with probability e^(ΔE/T)</li>
                    <li><strong>High T:</strong> e^(ΔE/T) ≈ 1 → accept most moves</li>
                    <li><strong>Low T:</strong> e^(ΔE/T) ≈ 0 → reject most bad moves</li>
                    <li><strong>Small |ΔE|:</strong> More likely to accept slightly bad moves</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Temperature Schedule Examples:</strong><br>
                    • Linear: T(t) = T₀ - αt<br>
                    • Exponential: T(t) = T₀ × γᵗ (where γ < 1)<br>
                    • Logarithmic: T(t) = T₀ / log(1 + t)
                </div>
                
                <h3>Algorithm Steps:</h3>
                <ul class="content-list">
                    <li><strong>Initialize:</strong> Start with high temperature T and random state</li>
                    <li><strong>Generate Neighbor:</strong> Create random successor state</li>
                    <li><strong>Calculate ΔE:</strong> Difference in objective function values</li>
                    <li><strong>Accept/Reject:</strong> Always accept if better, probabilistically if worse</li>
                    <li><strong>Cool Down:</strong> Reduce temperature according to schedule</li>
                    <li><strong>Repeat:</strong> Continue until temperature reaches minimum or time limit</li>
                </ul>
            </div>
        </div>

        <!-- Genetic Algorithms: Detailed Explanation -->
        <div class="slide progressive-concept">
            <h2>🧬 Genetic Algorithms: Evolution in Action</h2>
            
            <p style="margin-bottom: 30px; font-size: 1.2em;">Instead of maintaining a single solution, genetic algorithms maintain a <strong>population</strong> of solutions and evolve them over generations using principles inspired by natural selection.</p>
            
            <div class="image-container">
                <img src="images/ai/genetic-algorithm-process.png" alt="Genetic algorithm workflow showing initial population, fitness function evaluation, selection, crossover, and mutation steps with numerical examples" />
            </div>
            
            <div class="concept-steps">
                <div class="concept-step">
                    <div class="step-number">🧬</div>
                    <div class="step-content">
                        <h4>Population Initialization</h4>
                        <p>Start with a diverse population of random solutions (typically 50-1000 individuals). Each solution is encoded as a string (like DNA).</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">⭐</div>
                    <div class="step-content">
                        <h4>Fitness Evaluation</h4>
                        <p>Evaluate each individual using a fitness function (opposite of cost function). Better solutions get higher fitness scores and higher reproduction probability.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">👥</div>
                    <div class="step-content">
                        <h4>Selection for Reproduction</h4>
                        <p>Choose pairs of parents for breeding based on fitness. Common methods: roulette wheel selection, tournament selection, rank-based selection.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">🔀</div>
                    <div class="step-content">
                        <h4>Crossover (Recombination)</h4>
                        <p>Combine genetic material from two parents to create offspring. For strings, this might mean swapping segments at random crossover points.</p>
                    </div>
                </div>
                
                <div class="concept-step">
                    <div class="step-number">⚡</div>
                    <div class="step-content">
                        <h4>Mutation</h4>
                        <p>Randomly change small parts of offspring to maintain genetic diversity and explore new areas of the search space.</p>
                    </div>
                </div>
            </div>
            
            <div class="accent-box">
                <strong>8-Queens Example:</strong> Represent each solution as string "24748552" where position i contains row of queen in column i. Fitness = 28 - (number of attacking pairs). The diagram above shows how these genetic operations work together through selection, crossover, and mutation phases.
            </div>
        </div>

        <!-- Genetic Algorithm Example -->
        <div class="slide title-content">
            <h2>🧬 Genetic Algorithm: 8-Queens Example</h2>
            
            <div class="content-area">
                <p>Let's see how genetic algorithms work on 8-Queens with a concrete example of one generation.</p>
                
                <h3>Population Representation:</h3>
                <p>Each individual is a string of 8 digits representing queen positions:</p>
                <ul class="content-list">
                    <li><strong>Individual 1:</strong> "24748552" (fitness = 24)</li>
                    <li><strong>Individual 2:</strong> "32752411" (fitness = 23)</li>
                    <li><strong>Individual 3:</strong> "24415124" (fitness = 20)</li>
                    <li><strong>Individual 4:</strong> "32543213" (fitness = 11)</li>
                </ul>
                
                <div class="highlight-box">
                    <strong>Fitness Function:</strong> fitness = 28 - (attacking pairs)<br>
                    Maximum possible fitness is 28 (perfect solution), minimum is 0.
                </div>
                
                <h3>Selection Process:</h3>
                <p>Selection probabilities based on fitness:</p>
                <ul class="content-list">
                    <li><strong>Individual 1:</strong> 24/(24+23+20+11) = 31%</li>
                    <li><strong>Individual 2:</strong> 23/78 = 29%</li>
                    <li><strong>Individual 3:</strong> 20/78 = 26%</li>
                    <li><strong>Individual 4:</strong> 11/78 = 14%</li>
                </ul>
                
                <h3>Crossover Example:</h3>
                <p>Parent 1: "24748552" | Parent 2: "32752411"</p>
                <p>Crossover point after position 3:</p>
                <ul class="content-list">
                    <li><strong>Child 1:</strong> "247|52411" → "24752411"</li>
                    <li><strong>Child 2:</strong> "327|48552" → "32748552"</li>
                </ul>
                
                <div class="accent-box">
                    <strong>Mutation:</strong> With small probability (e.g., 1%), randomly change one digit in each child. Example: "24752411" → "24752413"
                </div>
            </div>
        </div>

        <!-- Comparing All Methods -->
        <div class="slide comparison">
            <h2>⚖️ Comparing Local Search Methods</h2>
            
            <div class="comparison-grid">
                <div class="comparison-item">
                    <h3>Hill Climbing Variants</h3>
                    <p><strong>Best For:</strong> Quick solutions, limited resources</p>
                    
                    <ul class="content-list">
                        <li><strong>Basic HC:</strong> Fast, simple, 14% success</li>
                        <li><strong>Sideways Moves:</strong> 94% success, more steps</li>
                        <li><strong>Random Restarts:</strong> Nearly 100% success</li>
                        <li><strong>Random Walk:</strong> Complete, tuneable</li>
                    </ul>
                    
                    <div class="highlight-box">
                        Simple to implement and understand
                    </div>
                </div>
                
                <div class="comparison-item">
                    <h3>Advanced Methods</h3>
                    <p><strong>Best For:</strong> Complex problems, high-quality solutions</p>
                    
                    <ul class="content-list">
                        <li><strong>Simulated Annealing:</strong> Theoretically optimal</li>
                        <li><strong>Genetic Algorithms:</strong> Population diversity</li>
                        <li><strong>Tabu Search:</strong> Memory-guided exploration</li>
                        <li><strong>Beam Search:</strong> Multiple parallel searches</li>
                    </ul>
                    
                    <div class="accent-box">
                        More sophisticated but complex to tune
                    </div>
                </div>
            </div>
            
            <div class="vs-divider">⚖️</div>
        </div>

        <!-- Final Quiz -->
        <div class="slide interactive-quiz">
            <h2>🎓 Final Challenge: Choosing the Right Algorithm</h2>
            
            <div class="quiz-question">
                <strong>Scenario:</strong> You're working on a real-time optimization system that needs to find good (not necessarily optimal) solutions for scheduling problems in under 1 second, with limited memory. Which approach would you choose?
            </div>
            
            <div class="quiz-options">
                <div class="quiz-option">A) Basic hill climbing</div>
                <div class="quiz-option">B) Hill climbing with random restarts</div>
                <div class="quiz-option">C) Simulated annealing</div>
                <div class="quiz-option">D) Genetic algorithm</div>
            </div>
            
            <button class="reveal-button" onclick="revealAnswer('quiz2')">Reveal Answer</button>
            
            <div class="quiz-answer" id="quiz2">
                <strong>Answer: B) Hill climbing with random restarts</strong><br>
                Given the constraints (real-time, limited memory, "good enough" solutions), random restarts provides the best balance: high success rate, predictable runtime, minimal memory usage, and easy implementation. It's the "Swiss Army knife" of local search - versatile, reliable, and practical for most real-world applications.
            </div>
        </div>

        <!-- Comprehensive Summary -->
        <div class="slide title-content">
            <h2>🎯 Complete Summary: Local Search Mastery</h2>
            
            <div class="content-area">
                <div class="highlight-box">
                    <strong>Core Principle:</strong> Local search trades completeness for efficiency, focusing on finding good solutions quickly rather than guaranteeing optimal solutions.
                </div>
                
                <h3>Algorithm Hierarchy (Simple → Complex):</h3>
                <ul class="content-list">
                    <li><strong>Basic Hill Climbing:</strong> Greedy local search, fast but often gets stuck</li>
                    <li><strong>Hill Climbing + Sideways:</strong> Escapes plateaus, much better success rate</li>
                    <li><strong>Random Restarts:</strong> Multiple attempts, practical gold standard</li>
                    <li><strong>Random Walk:</strong> Probabilistic mix of greedy and random moves</li>
                    <li><strong>Simulated Annealing:</strong> Temperature-controlled acceptance of bad moves</li>
                    <li><strong>Genetic Algorithms:</strong> Population-based evolution with crossover and mutation</li>
                </ul>
                
                <h3>Problem Types and Best Methods:</h3>
                <ul class="content-list">
                    <li><strong>Discrete Optimization:</strong> Hill climbing variants work well</li>
                    <li><strong>Continuous Optimization:</strong> Gradient descent or simulated annealing</li>
                    <li><strong>Combinatorial Problems:</strong> Genetic algorithms or specialized operators</li>
                    <li><strong>Multi-Modal Landscapes:</strong> Random restarts or population methods</li>
                </ul>
                
                <div class="accent-box">
                    <strong>When to Use Local Search:</strong><br>
                    ✓ Large search spaces where systematic search is impractical<br>
                    ✓ Optimization problems where path doesn't matter<br>
                    ✓ Time-critical applications needing quick solutions<br>
                    ✓ Memory-constrained environments<br>
                    ✓ Problems where "good enough" solutions are acceptable
                </div>
                
                <p><strong>Real-World Impact:</strong> These algorithms power machine learning training, circuit design, scheduling systems, game AI, financial optimization, and countless other applications where finding excellent solutions quickly is more valuable than guaranteeing perfect solutions slowly.</p>
                
                <p>You now understand the foundations of modern optimization - from simple hill climbing to sophisticated evolutionary algorithms. These tools are essential for any AI practitioner tackling real-world optimization challenges!</p>
            </div>
        </div>

    </div>

    <!-- Enhanced Slide Counter -->
    <div class="slide-counter" id="slideCounter">
        Slide 1 of 22
    </div>

    <script>
        // Enhanced Intersection Observer for slide animations
        const slides = document.querySelectorAll('.slide');
        const progressBar = document.getElementById('progressBar');
        const slideCounter = document.getElementById('slideCounter');

        const observerOptions = {
            threshold: 0.3,
            rootMargin: '0px 0px -100px 0px'
        };

        const slideObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    // Add visible class for animations
                    entry.target.classList.add('visible');
                    
                    // Update progress bar and counter
                    const slideIndex = Array.from(slides).indexOf(entry.target);
                    const progress = ((slideIndex + 1) / slides.length) * 100;
                    progressBar.style.width = progress + '%';
                    slideCounter.textContent = `Slide ${slideIndex + 1} of ${slides.length}`;
                }
            });
        }, observerOptions);

        // Observe all slides
        slides.forEach(slide => {
            slideObserver.observe(slide);
        });

        // Enhanced keyboard navigation
        document.addEventListener('keydown', (e) => {
            let currentSlide = 0;
            
            // Find current slide
            slides.forEach((slide, index) => {
                const rect = slide.getBoundingClientRect();
                if (rect.top <= 200 && rect.bottom >= 200) {
                    currentSlide = index;
                }
            });
            
            // Navigate with arrow keys
            if (e.key === 'ArrowDown' || e.key === 'ArrowRight' || e.key === ' ') {
                e.preventDefault();
                if (currentSlide < slides.length - 1) {
                    slides[currentSlide + 1].scrollIntoView({ 
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            } else if (e.key === 'ArrowUp' || e.key === 'ArrowLeft') {
                e.preventDefault();
                if (currentSlide > 0) {
                    slides[currentSlide - 1].scrollIntoView({ 
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            } else if (e.key === 'Home') {
                e.preventDefault();
                slides[0].scrollIntoView({ behavior: 'smooth', block: 'start' });
            } else if (e.key === 'End') {
                e.preventDefault();
                slides[slides.length - 1].scrollIntoView({ behavior: 'smooth', block: 'start' });
            }
        });

        // Interactive quiz functionality
        function revealAnswer(quizId) {
            const answer = document.getElementById(quizId);
            answer.classList.add('visible');
            
            // Add success animation
            const button = event.target;
            button.style.background = '#059669';
            button.textContent = '✓ Answer Revealed';
            button.disabled = true;
        }

        // Initialize
        setTimeout(() => {
            if (slides[0]) {
                slides[0].classList.add('visible');
            }
        }, 100);

        // Add smooth scrolling behavior for better UX
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
